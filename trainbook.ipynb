{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers.data import get_dataloaders\n",
    "from helpers.train import TrainingManager\n",
    "from helpers.loss_accuracy import accuracy\n",
    "from functools import partial\n",
    "import models.resnet\n",
    "import torch\n",
    "import argparse\n",
    "import torch.optim as optim\n",
    "from torch.nn import CrossEntropyLoss\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import ImageNet\n",
    "import torch.utils.data\n",
    "import torchvision.transforms as transforms\n",
    "def get_dataloaders(dataset_name, batch_size, num_workers=20):\n",
    "    trainset, testset = _datasets_get_func[dataset_name]()\n",
    "    dataloader = partial(torch.utils.data.DataLoader, batch_size=batch_size, num_workers=num_workers, pin_memory=True)\n",
    "    return dataloader(trainset, shuffle=True), dataloader(testset)\n",
    "        \n",
    "    \n",
    "    batch_size, num_workers\n",
    "\n",
    "_datasets_base_folder = '/media/data1/idokessler'\n",
    "_datasets_get_func = {}\n",
    "_imagenet_folder = '/media/data1/nadavz/data/imagenet/'\n",
    "\n",
    "_normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "_transform_test_cifar10 = transforms.Compose([\n",
    "                                        transforms.ToTensor(), _normalize])\n",
    "_transform_train_cifar10 = transform=transforms.Compose([\n",
    "                                        transforms.RandomHorizontalFlip(),\n",
    "                                        transforms.ColorJitter(0.3,0.3,0.3,0.3),\n",
    "                                        transforms.ToTensor(),\n",
    "                                        transforms.RandomErasing(), _normalize])\n",
    "def _get_imagenet():\n",
    "    return ImageNet(root=_imagenet_folder, split='train', transform=_transform_train_cifar10), \\\n",
    "            ImageNet(root=_imagenet_folder, split='val', transform=_transform_test_cifar10)\n",
    "\n",
    "_datasets_get_func['imagenet'] = _get_imagenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "('Meta file not found or corrupted.', 'You can use download=True to create it.')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-5cca595b0465>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_dataloaders\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'imagenet'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-18-5610d8dae4ac>\u001b[0m in \u001b[0;36mget_dataloaders\u001b[0;34m(dataset_name, batch_size, num_workers)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_dataloaders\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mtrainset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_datasets_get_func\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mdataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_workers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpin_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-5610d8dae4ac>\u001b[0m in \u001b[0;36m_get_imagenet\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m                                         transforms.RandomErasing(), _normalize])\n\u001b[1;32m     24\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_get_imagenet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mImageNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_imagenet_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_transform_train_cifar10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0mImageNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_imagenet_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_transform_test_cifar10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dl-env/lib/python3.6/site-packages/torchvision/datasets/imagenet.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, split, download, **kwargs)\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0mwnid_to_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_meta_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImageNet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dl-env/lib/python3.6/site-packages/torchvision/datasets/imagenet.py\u001b[0m in \u001b[0;36m_load_meta_file\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m             raise RuntimeError(\"Meta file not found or corrupted.\",\n\u001b[0;32m--> 108\u001b[0;31m                                \"You can use download=True to create it.\")\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_save_meta_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwnid_to_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_wnids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: ('Meta file not found or corrupted.', 'You can use download=True to create it.')"
     ]
    }
   ],
   "source": [
    "trainloader, testloader = get_dataloaders('imagenet', bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] -in_c IN_C -r R R R -b B B B -c C C C -bs BS\n",
      "                             -lr LR [--trial] [--load]\n",
      "ipykernel_launcher.py: error: the following arguments are required: -in_c, -r, -b, -c, -bs, -lr\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/idokessler/dl-env/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3327: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('-in_c', type=int, required=True)\n",
    "parser.add_argument('-r', type=int, required=True, nargs=3)\n",
    "parser.add_argument('-b', type=int, required=True, nargs=3)\n",
    "parser.add_argument('-c', type=int, required=True, nargs=3)\n",
    "parser.add_argument('-bs', type=int, required=True)\n",
    "parser.add_argument('-lr', type=float, required=True)\n",
    "parser.add_argument('--trial', dest='is_trial', action='store_true')\n",
    "parser.add_argument('--load', dest='load', action='store_true')\n",
    "parser.set_defaults(is_trial=False, load=False)\n",
    "args = parser.parse_args()\n",
    "in_planes_parameter = args.in_c\n",
    "repeats_parameter = args.r\n",
    "num_blocks_parameters = args.b\n",
    "num_channels_parameters = args.c\n",
    "is_trial = args.is_trial\n",
    "load = args.load\n",
    "lr = args.lr\n",
    "bs = args.bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_planes_parameter = 16\n",
    "repeats_parameter = [1, 1, 1]\n",
    "num_blocks_parameters = [3, 3, 3]\n",
    "num_channels_parameters=[16, 32, 64]\n",
    "is_trial = False\n",
    "load = False\n",
    "lr = 2e-4\n",
    "bs = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "trainloader, testloader = get_dataloaders('cifar10', bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "_Conv2d = partial(nn.Conv2d, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "_BN2d = nn.BatchNorm2d\n",
    "_act = partial(nn.ReLU, inplace=True)\n",
    "\n",
    "class WeightChangingConv(nn.Module):\n",
    "    def __init__(self, in_c, out_c, kernel_size=3, stride=1, padding=0):\n",
    "        super(WeightChangingConv, self).__init__()\n",
    "        self.w_size = (out_c, in_c, kernel_size, kernel_size)\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        self.w_base_weights = nn.Parameter(\n",
    "            nn.init.kaiming_uniform_(torch.Tensor(1, *self.w_size)))\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.avgpool = nn.Sequential(nn.AdaptiveAvgPool2d(1), nn.Flatten())\n",
    "        self.maxpool = nn.Sequential(nn.AdaptiveMaxPool2d(1), nn.Flatten())\n",
    "        self.w_creator = nn.Linear(out_c*2, np.prod(self.w_size), bias=False)\n",
    "        self.w_input_first = nn.Parameter(torch.Tensor(1, out_c, 1, 2).normal_(std=1e-5))\n",
    "        \n",
    "    def metaconv(self, x, w):\n",
    "        w_ = w.reshape(w.shape[0] * w.shape[1], *w.shape[2:])\n",
    "        x_ = x.reshape(1, x.shape[0] * x.shape[1], *x.shape[2:])\n",
    "        out = F.conv2d(x_, w_, None, stride=self.stride,\n",
    "                       groups=x.shape[0], padding=self.padding)\n",
    "        return out.reshape(x.shape[0], w.shape[1], *out.shape[2:])\n",
    "\n",
    "    def get_w_delta(self, x, w_input):\n",
    "        if w_input is None:\n",
    "            w_input = self.w_input_first.expand(x.shape[0], -1, -1, -1)\n",
    "            w = self.w_base_weights.expand(x.shape[0], -1, -1, -1, -1)\n",
    "        else:\n",
    "            w_input, w = w_input\n",
    "\n",
    "        features = self.tanh(torch.cat((self.avgpool(w_input), self.maxpool(w_input)), 1))\n",
    "        w_delta = self.tanh(self.w_creator(features).reshape((-1, *self.w_size)))\n",
    "        return w * 0.97 + w_delta * 0.03\n",
    "\n",
    "    def forward(self, x, w_input=None):\n",
    "        w = self.get_w_delta(x, w_input)\n",
    "        return self.metaconv(x, w), w\n",
    "        \n",
    "class BasicBlockFB(nn.Module):\n",
    "    def __init__(self, in_planes, planes, stride=1, repeats=1, prob_1=0.5):\n",
    "        super(BasicBlockFB, self).__init__()\n",
    "        self.repeats = repeats\n",
    "        self.prob_1 = prob_1\n",
    "        conv = WeightChangingConv if repeats != 1 else _Conv2d\n",
    "        self.conv1 = conv(in_planes, planes, stride=stride)\n",
    "        self.bn1 = nn.ModuleList([_BN2d(planes) for i in range(2*self.repeats-1)])\n",
    "        self.seq = nn.Sequential(_act(), _Conv2d(planes, planes), _BN2d(planes))\n",
    "        self.shortcut = \\\n",
    "            nn.Sequential(_Conv2d(in_planes, planes, kernel_size=1, stride=stride, padding=(stride-1)//2), _BN2d(planes)) \\\n",
    "            if stride != 1 or in_planes != planes else nn.Sequential()\n",
    "\n",
    "    def forward(self, x):\n",
    "        extra_conv1_data = []\n",
    "        shortcut = self.shortcut(x)\n",
    "        repeats = self.repeats\n",
    "        if self.training: \n",
    "            repeats = [1, random.randint(1, self.repeats * 2 - 1)][random.uniform(0,1) > self.prob_1]\n",
    "        for i in range(repeats):\n",
    "            res = self.conv1(x, *extra_conv1_data)\n",
    "            res, w = res if type(res) == tuple else (res, torch.tensor(1))\n",
    "            res = F.relu(self.seq(self.bn1[i](res)) + shortcut, inplace=True)\n",
    "            extra_conv1_data = [(res, w)]\n",
    "        return res\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, in_planes, repeats=[3, 3, 3], num_blocks=[3, 3, 3], num_channels=[16, 32, 64], num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = in_planes\n",
    "        self.pre_layer = nn.Sequential(_Conv2d(3, self.in_planes), _BN2d(self.in_planes), _act())\n",
    "        self.layer1 = self._make_layer(repeats[0], num_channels[0], num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(repeats[1], num_channels[1], num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(repeats[2], num_channels[2], num_blocks[2], stride=2)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1), nn.Flatten(),\n",
    "            nn.Linear(self.in_planes, num_classes)\n",
    "        )\n",
    "\n",
    "    def _make_layer(self, repeat, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1] * (num_blocks - 1)\n",
    "        repeats = [1] * (num_blocks - 1) + [repeat]\n",
    "        layers = []\n",
    "        for stride, repeat in zip(strides, repeats):\n",
    "            layers.append(BasicBlockFB(self.in_planes, planes, stride, repeat))\n",
    "            self.in_planes = planes\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pre_layer(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        return self.classifier(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Residual(nn.Module):\n",
    "    def __init__(self, *seq_models):\n",
    "        super(Residual, self).__init__()\n",
    "        self._model = nn.Sequential(*seq_models)\n",
    "    def forward(self, x):\n",
    "        return x + self._model(x)\n",
    "\n",
    "def conv_bn_act(in_c, out_c, kernel_size=1, padding=0, stride=1, groups=1, is_bn=True, is_act=True, conv=_Conv2d, bn=_BN2d, act=_act):\n",
    "    return nn.Sequential(\n",
    "        conv(in_c, out_c, kernel_size=kernel_size, padding=padding, stride=stride, groups=groups),\n",
    "        bn(out_c) if is_bn else nn.Identity(),\n",
    "        act() if is_act else nn.Identity()\n",
    "    )\n",
    "\n",
    "def ibconv(c, mid_c, kernel_size=3):\n",
    "    return Residual(\n",
    "            conv_bn_act(c,mid_c),\n",
    "            conv_bn_act(mid_c,mid_c,kernel_size=kernel_size, padding=(kernel_size-1)//2, groups=mid_c),\n",
    "            conv_bn_act(mid_c,c)\n",
    "        )\n",
    "\n",
    "def ResNet(num_classes=10):\n",
    "    return nn.Sequential(\n",
    "        conv_bn_act(3,32,kernel_size=5, padding=2, stride=1),\n",
    "        conv_bn_act(32,64,kernel_size=5, padding=2, stride=2),\n",
    "        ibconv(64, 512),\n",
    "        ibconv(64, 512),\n",
    "        ibconv(64, 512),\n",
    "        conv_bn_act(64,128,kernel_size=3, padding=1, stride=2),\n",
    "        ibconv(128, 1024),\n",
    "        ibconv(128, 1024),\n",
    "        ibconv(128, 1024),\n",
    "        conv_bn_act(128,128, stride=1, kernel_size=3),\n",
    "        nn.AdaptiveAvgPool2d(1), nn.Flatten(),\n",
    "        nn.Linear(128, num_classes)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = ResNet(in_planes=in_planes_parameter, \n",
    "#                repeats=repeats_parameter, num_blocks=num_blocks_parameters, num_channels=num_channels_parameters)\n",
    "model = ResNet()\n",
    "model = model.to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=.1, \n",
    "                      momentum=0.9, nesterov=True)\n",
    "def lr_func(it):\n",
    "    if it<1000:\n",
    "        return 10 ** (-2 + (it / 1000) * (1.5))\n",
    "    elif it < 10000:\n",
    "        return 10 ** (-0.5 - ((it - 1000) / 10000) * 4)\n",
    "    else:\n",
    "        return 0.0001\n",
    "lr_scheduler = optim.lr_scheduler.CyclicLR(optimizer, 1e-4, 1e-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# optimizer.step()\n",
    "# x = []\n",
    "# for i in range(100000):\n",
    "#     lr_scheduler.step()\n",
    "#     x.append(lr_scheduler.get_lr())\n",
    "# plt.plot(x)\n",
    "# plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_int(l):\n",
    "    return '_'.join(map(str, l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_name = f\"resnet_with_feedback_1x1_inc_{in_planes_parameter}_repeats_{join_int(repeats_parameter)}_\" + \\\n",
    "    f\"num_blocks_{join_int(num_blocks_parameters)}_num_channels_{join_int(num_channels_parameters)}_\" + \\\n",
    "    f\"lr_{lr}_bs_{bs}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tm = TrainingManager(trial_name, load=load, is_trial=is_trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training trial: \u001b[34mresnet_with_feedback_1x1_inc_16_repeats_1_1_1_num_blocks_3_3_3_num_channels_16_32_64_lr_0.0002_bs_32\u001b[0m \u001b[31mis_trial\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{tr_loss: 0.61352, tr_acc: 0.78853, te_loss: 0.59492, te_acc: 0.79753}: 100%|██████████| 10000/10000 [04:30<00:00, 36.99it/s]\n"
     ]
    }
   ],
   "source": [
    "tm.train(model, optimizer,\n",
    "         trainloader, testloader,\n",
    "         CrossEntropyLoss(), CrossEntropyLoss(),\n",
    "         accuracy, accuracy, lr_scheduler=lr_scheduler, device=device, no_iterations=10000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
